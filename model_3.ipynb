{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import sklearn as sk\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "PATH = \"video_data/surveillance_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_frames(p):\n",
    "    #assert os.path.exists(p)\n",
    "    cap = cv2.VideoCapture(p)\n",
    "    \n",
    "    #assert cap\n",
    "    rate = math.floor(cap.get(3))\n",
    "\n",
    "    ImageFrames = []\n",
    "    #assert cap.isOpened()\n",
    "    \n",
    "\n",
    "    '''make sure to figure out how to extract a certain amount of frames so you don't use too much memory'''\n",
    "    while cap.isOpened():\n",
    "        #ID = cap.get(1)\n",
    "        \n",
    "        success, image = cap.read()\n",
    "        n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        mid = int(n_frames/2)\n",
    "        first_q = int(n_frames/4)\n",
    "        third_q = int(n_frames * .75)\n",
    "        end = n_frames\n",
    "        #print(n_frames)\n",
    "        #assert success\n",
    "\n",
    "        if success:\n",
    "\n",
    "            for frame in range(n_frames):\n",
    "                if frame == first_q or frame == mid or frame == third_q or frame == end:\n",
    "                    \n",
    "                    \n",
    "                    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                    ImageFrames.append(image)\n",
    "                else: continue\n",
    "            cap.release()\n",
    "    #print(\"successful frame capture\")\n",
    "            return ImageFrames\n",
    "\n",
    "        else: \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:03<00:00, 38.87it/s]\n",
      "100%|██████████| 150/150 [00:03<00:00, 39.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CATEGORIES = [\"fight\", \"noFight\"]\n",
    "X_set = []\n",
    "y_set = []\n",
    "for category in os.listdir(PATH):\n",
    "    \n",
    "    \n",
    "    path = os.path.join(PATH, category)\n",
    "    #print(path)\n",
    "    #assert os.path.exists(path)\n",
    "\n",
    "\n",
    "    class_num = CATEGORIES.index(category)\n",
    "    for i, video in tqdm(enumerate(os.listdir(path)), total=len(os.listdir(path))):\n",
    "\n",
    "        #print(path + '/' + video)\n",
    "        #print(os.path.join(path, video))\n",
    "        frames = video_to_frames(path + '/' + video)\n",
    "        if frames:\n",
    "        \n",
    "            for j, frame in enumerate(frames):\n",
    "                X_set.append(frame)\n",
    "                y_set.append(class_num)\n",
    "        else: continue\n",
    "\n",
    "            \n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 900)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_set = np.array(X_set).reshape(-1 , IMG_SIZE * IMG_SIZE * 3)\n",
    "y_set = np.array(y_set)\n",
    "len(X_set), len(y_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "\n",
    "stratified_sample = StratifiedShuffleSplit(n_splits=2, test_size=0.2)\n",
    "\n",
    "for train_index, test_index in stratified_sample.split(X_set, y_set):\n",
    "    X_train, X_test = X_set[train_index], X_set[test_index]\n",
    "    y_train, y_test = y_set[train_index], y_set[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, IMG_SIZE, IMG_SIZE, 3) / 255\n",
    "X_test_nn = X_test.reshape(-1, IMG_SIZE, IMG_SIZE, 3) / 255\n",
    "# X_val = X_val.reshape(-1, IMG_SIZE, IMG_SIZE, 3) / 255\n",
    "\n",
    "y_train = np.asarray(y_train)\n",
    "y_test_nn = np.asarray(y_test)\n",
    "# y_val = np.asarray(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, 16)\n",
    "test_gen = DataGenerator(X_test_nn, y_test_nn, 16)\n",
    "# val_gen = DataGenerator(X_val, y_val, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, layers\n",
    "\n",
    "# data_augmentation = Sequential(\n",
    "#     [\n",
    "#         layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "#         layers.RandomRotation(0.1),\n",
    "#         layers.RandomZoom(0.1),\n",
    "#         layers.RandomContrast(factor=0.1),\n",
    "#         layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "#     ],\n",
    "#     name=\"img_augmentation\"\n",
    "# )\n",
    "data_augmentation = Sequential(\n",
    "    [\n",
    "        layers.RandomRotation(factor=0.15),\n",
    "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        layers.RandomFlip(),\n",
    "        layers.RandomContrast(factor=0.1),\n",
    "    ],\n",
    "    name=\"img_augmentation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, data_aug, trainable=True, dropout=0.5):\n",
    "        inputs = keras.Input(shape=input_shape)\n",
    "        x = data_aug(inputs)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        baseModel = MobileNetV2(weights=None, \n",
    "                                   pooling='avg',\n",
    "                                   include_top=False, \n",
    "                                   input_tensor=x)\n",
    "        baseModel.trainable = trainable\n",
    "\n",
    "        headModel = baseModel.output\n",
    "        headModel = layers.Dropout(dropout)(headModel)\n",
    "\n",
    "        outputs = layers.Dense(1, activation=\"sigmoid\")(headModel) # formerly outputs = \n",
    "\n",
    "        #headModel = layers.GlobalAveragePooling2D()(headModel)\n",
    "        model = Model(inputs = baseModel.input, outputs=outputs)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MobNet = build_model(input_shape=(224,224) + (3,),\n",
    "                     data_aug= data_augmentation,\n",
    "                     trainable=True,\n",
    "                     dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=15, mode='min', min_delta=0.0001)\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras.losses' has no attribute 'BiaryCrossentropy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m mets \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mbinary_accuracy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39macc\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlosses\u001b[39m.\u001b[39;49mBiaryCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m MobNet\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mloss,\n\u001b[0;32m      4\u001b[0m                optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m                metrics\u001b[39m=\u001b[39mmets)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.api._v2.keras.losses' has no attribute 'BiaryCrossentropy'"
     ]
    }
   ],
   "source": [
    "mets = ['binary_accuracy', 'acc']\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "MobNet.compile(loss=loss,\n",
    "               optimizer='adam',\n",
    "               metrics=mets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "history = MobNet.fit(train_gen,\n",
    "                     batch_size=4,\n",
    "                     epochs=25, \n",
    "                     steps_per_epoch= len(train_gen),\n",
    "                    #  callbacks= callbacks,\n",
    "                     #validation_data=val_gen,                    \n",
    "                     verbose=1)\n",
    "\n",
    "print(\"Training Complete.\")\n",
    "end_time = datetime.datetime.now()\n",
    "print(f\"Training time: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model):\n",
    "    acc = model.evaluate(test_gen)\n",
    "    print(\"This model's accuracy is:\", round(acc[1], 4)*100 , \"%\")\n",
    "\n",
    "\n",
    "eval_model(MobNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_performance(model_hist):\n",
    "    graph = pd.DataFrame(model_hist.history).plot(figsize=(10,7), title=\"MobileNetV2 Training Performance\", xlabel=\"Epochs\")\n",
    "\n",
    "\n",
    "\n",
    "view_performance(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba3a49a2d89a21dd1fa2c7b5d6b7fcd2a31de042e8686c95cc798c595b19bacd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
